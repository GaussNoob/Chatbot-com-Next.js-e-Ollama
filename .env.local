# .env.local

# Nome do Chatbot exibido na interface
NEXT_PUBLIC_CHATBOT_NAME="Meu Chatbot Incrível"

# Nome do modelo Ollama a ser usado (deve ser o mesmo que você baixou via 'ollama pull')
OLLAMA_MODEL_NAME="deepseek-r1"

# URL base do seu servidor Ollama
OLLAMA_BASE_URL="http://localhost:11434"
